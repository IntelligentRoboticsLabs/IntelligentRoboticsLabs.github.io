<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[RSS Feed]]></title><description><![CDATA[Robotics Laboratory and %TOPICS%]]></description><link>https://IntelligentRoboticsLabs.github.io</link><generator>GatsbyJS</generator><lastBuildDate>Sun, 07 Feb 2021 23:30:53 GMT</lastBuildDate><item><title><![CDATA[Pepper, the Reception Assistant Robot]]></title><description><![CDATA[In this project Pepper becomes an assistant receptionist in the Acciona's office.]]></description><link>https://IntelligentRoboticsLabs.github.io/pepper_assistant</link><guid isPermaLink="false">https://IntelligentRoboticsLabs.github.io/pepper_assistant</guid><pubDate>Wed, 20 Jan 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;In this project Pepper becomes an assistant receptionist in the Acciona&apos;s office. Among its main functions are to guide visitors to the different meeting rooms, to book a restaurant nearby, to book a taxi or to notify your arrival with a phone call to the meeting host. The robot has a Natural Language Processing (NLP) module to improve the Human-Robot interaction. &lt;/p&gt;</content:encoded></item><item><title><![CDATA[Robobo]]></title><description><![CDATA[Robobo project combines a simple mobile base with a smartphone to create complete mobile educational robots.]]></description><link>https://IntelligentRoboticsLabs.github.io/robobo</link><guid isPermaLink="false">https://IntelligentRoboticsLabs.github.io/robobo</guid><pubDate>Tue, 19 Jan 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;a href=&quot;https://theroboboproject.com/en/?lang=en&quot;&gt;Robobo project&lt;/a&gt; combines a simple mobile base with a smartphone to create complete mobile educational robots. The framework is organized into three skill levels:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Scratch blocks for starting programmers,&lt;/li&gt;
&lt;li&gt;Python and JavaScript libraries for intermediate ones,&lt;/li&gt;
&lt;li&gt;and JAVA Android or ROS libraries for advanced users.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these features, this project has tried to develop the framework for more advanced users in ROS2. It consists of a series of ROS2 nodes that offer services to be able to send commands to the base, such as publishers who update the state of the robot, in addition to offering the information collected by the mobile camera that is located above the base. This technology has been developed for iOS and Android phones.&lt;/p&gt;
&lt;p&gt;Check out our works on iOS and ROS2 &lt;a href=&quot;https://github.com/mintforpeople/robobo-app-ios/tree/feature-ros2&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Check out our works on Android and ROS2 &lt;a href=&quot;https://github.com/mintforpeople/robobo-remote-control-ros2&quot;&gt;here&lt;/a&gt;. &lt;/p&gt;</content:encoded></item><item><title><![CDATA[Navigation Course]]></title><description><![CDATA[The ROS/ROS2 navigation stack is one of its main packages and it allow to give a robot basic capacities of movement in an easy way]]></description><link>https://IntelligentRoboticsLabs.github.io/navigation</link><guid isPermaLink="false">https://IntelligentRoboticsLabs.github.io/navigation</guid><pubDate>Wed, 08 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;The ROS/ROS2 navigation stack is one of its main packages and it allow to give a robot basic capacities of movement in an easy way. Also, the navigation package provide us a high flexibility, making it perfect for ensuring a fast deployment of the robot in an industrial or domestic environment.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Main concepts about ROS/ROS2 navigation.&lt;/li&gt;
&lt;li&gt;Maps creation, SLAM.&lt;/li&gt;
&lt;li&gt;Localization system knowledge.&lt;/li&gt;
&lt;li&gt;Parameters usage for adopting the system to the environment.&lt;/li&gt;
&lt;li&gt;Trials on simulated and real robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;485&quot; src=&quot;https://www.youtube.com/embed/OklxMhdDfe0&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:encoded></item><item><title><![CDATA[Perception]]></title><description><![CDATA[Sensors are a data source very important for robots. Because of them, they can recognize its environment and get information very valious about it.]]></description><link>https://IntelligentRoboticsLabs.github.io/perception</link><guid isPermaLink="false">https://IntelligentRoboticsLabs.github.io/perception</guid><pubDate>Tue, 07 Jul 2020 00:00:00 GMT</pubDate><content:encoded>&lt;h2 id=&quot;description&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#description&quot; aria-label=&quot;description permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Description&lt;/h2&gt;
&lt;p&gt;Sensors are a data source very important for robots. Because of them, they can recognize its environment and get information very valious about it.&lt;/p&gt;
&lt;p&gt;Specifically, the camera is the most complex sensor that exist and, at the same time, it provide a great flow of data. Thank of that, useful algorithms can be elaborated for robot environment recognition. For example, &lt;strong&gt;Neural Networks&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&quot;course-targets&quot; style=&quot;position:relative;&quot;&gt;&lt;a href=&quot;#course-targets&quot; aria-label=&quot;course targets permalink&quot; class=&quot;anchor before&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; focusable=&quot;false&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Course Targets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Most common robot sensors types.&lt;/li&gt;
&lt;li&gt;Getting data by the sensors.&lt;/li&gt;
&lt;li&gt;2D processing of cameras information with OpenCV.&lt;/li&gt;
&lt;li&gt;3D sensorial data management.&lt;/li&gt;
&lt;li&gt;3D processing of RGBD cameras information with &lt;strong&gt;PCL&lt;/strong&gt; (Point Cloud Library).&lt;/li&gt;
&lt;li&gt;Trials with simulated and real robots.&lt;/li&gt;
&lt;/ul&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;485&quot; src=&quot;https://www.youtube.com/embed/262S-Z1o4tw&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;</content:encoded></item></channel></rss>